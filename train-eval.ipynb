{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "fgUBlclwDxc2",
    "outputId": "1c4ae556-690b-4277-faba-ee1135286400"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug  6 15:34:21 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   45C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRWNJyRtDxc9"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/NVIDIA/apex /apex\n",
    "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" /apex/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "AbYDWNHqDxdD",
    "outputId": "13a549f9-fdaf-4023-8996-7b765336fe19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
      "datasets  datasets.zip\tmodels\ttrain-eval.ipynb\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "!ls \"/content/gdrive/My Drive/lab/SSD/\"\n",
    "gdrive_dir = \"/content/gdrive/My Drive/lab/SSD/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "I0_DA3T4DxdK",
    "outputId": "96d6e93f-e894-45bc-817c-e7bc71dc9c81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'single-shot-detection-pytorch'...\n",
      "remote: Enumerating objects: 40, done.\u001b[K\n",
      "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
      "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
      "remote: Total 40 (delta 21), reused 28 (delta 11), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (40/40), done.\n"
     ]
    }
   ],
   "source": [
    "!unzip -q \"/content/gdrive/My Drive/lab/SSD/trainval.zip\" -d \"/content\"\n",
    "!git clone https://github.com/ncthuan/single-shot-detection-pytorch\n",
    "!cp single-shot-detection-pytorch/*.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FM286mawDxdQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.cuda as cuda\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from dataset import VOCDataset, collate_fn\n",
    "from model import SSD300, MultiBoxLoss\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-ZAhMWoDxdV"
   },
   "outputs": [],
   "source": [
    "#from apex import amp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KqWYYcDRDxdb"
   },
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 17202 training images. Files have been saved to output_folder: datasets/.\n",
      "\n",
      "There are 4301 validation images. Files have been saved to output_folder: datasets/.\n"
     ]
    }
   ],
   "source": [
    "from utils import create_data_lists\n",
    "voc07_path = os.path.join('datasets/', 'VOC2007/')\n",
    "voc12_path = os.path.join('datasets/', 'VOC2012/')\n",
    "create_data_lists(voc07_path, voc12_path, output_folder='datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "trainset = VOCDataset(data_folder='datasets/', json_files=('TRAIN_images.json', 'TRAIN_objects.json'), augment=True)\n",
    "valset = VOCDataset(data_folder='datasets/', json_files=('VAL_images.json', 'VAL_objects.json'))\n",
    "\n",
    "dataloaders = dict(\n",
    "    train = DataLoader(trainset, batch_size=8, collate_fn=collate_fn, shuffle=True, num_workers=2),\n",
    "    val = DataLoader(valset, batch_size=64, collate_fn=collate_fn, shuffle=False, num_workers=4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_objects_stat(dataset):\n",
    "    targets = dataset.targets\n",
    "    objects = list()\n",
    "    for target in targets:\n",
    "        objects.extend(target['labels'])\n",
    "    print('Total number of annotated objects:', len(objects))\n",
    "    sns.countplot(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aeroplane': 1,\n",
       " 'bicycle': 2,\n",
       " 'bird': 3,\n",
       " 'boat': 4,\n",
       " 'bottle': 5,\n",
       " 'bus': 6,\n",
       " 'car': 7,\n",
       " 'cat': 8,\n",
       " 'chair': 9,\n",
       " 'cow': 10,\n",
       " 'diningtable': 11,\n",
       " 'dog': 12,\n",
       " 'horse': 13,\n",
       " 'motorbike': 14,\n",
       " 'person': 15,\n",
       " 'pottedplant': 16,\n",
       " 'sheep': 17,\n",
       " 'sofa': 18,\n",
       " 'train': 19,\n",
       " 'tvmonitor': 20,\n",
       " 'background': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of annotated objects: 49949\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_objects_stat(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of annotated objects: 12250\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD4CAYAAAAdIcpQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAao0lEQVR4nO3df5TddX3n8eeLgBDQlNBMMMzEDcsGa8ipwcxms8VSSjwS0BJAsOEoZCtu2JzQBbddJdXT4tqcQy2opZV0gyABEUz5YSIFJaai61kgTjCQX6RMm0iGDJkB1yW250QD7/3j+5ntt5M7873fO/O9c5N5Pc65537v+37fn/u+k2/u+35/3O9XEYGZmdlwjhnrAszMrPW5WZiZWSE3CzMzK+RmYWZmhdwszMys0LFjXUBVpkyZEjNmzBjrMszMjiibN29+NSLaBseP2mYxY8YMurq6xroMM7MjiqSf1Ip7M5SZmRVyszAzs0JuFmZmVsjNwszMClXeLCRNkPRjSY+mx6dI2iDpxXQ/OTfvCkndknZJuiAXnytpa3ruNkmqum4zM/sXzVizuB7YmXt8I7AxImYCG9NjJM0CFgNnAQuB2yVNSDmrgKXAzHRb2IS6zcwsqbRZSOoAPgB8JRdeBKxJ02uAS3LxByLiYETsBrqBeZKmAZMi4qnITpF7Ty7HzMyaoOo1iy8BnwTezMVOjYhegHQ/NcXbgb25+XpSrD1ND44fRtJSSV2Suvr7+0fnHZiZWXXNQtIHgb6I2FxvSo1YDBM/PBixOiI6I6Kzre2wHyCamVmDqvwF9znAxZIuAk4AJkn6GrBf0rSI6E2bmPrS/D3A9Fx+B7AvxTtqxM3sKPHlR/aXzll+6akVVGJDqWzNIiJWRERHRMwg23H9dxHxUWA9sCTNtgRYl6bXA4slHS/pdLId2ZvSpqoDkuano6CuzuWYmVkTjMW5oW4G1kq6BngJuAIgIrZLWgvsAA4ByyPijZSzDLgbmAg8nm5mZtYkTWkWEfEk8GSafg1YMMR8K4GVNeJdwOzqKjQzs+H4F9xmZlbIzcLMzAq5WZiZWSE3CzMzK+RmYWZmhdwszMyskJuFmZkVcrMwM7NCbhZmZlbIzcLMzAq5WZiZWSE3CzMzK+RmYWZmhdwszMyskJuFmZkVcrMwM7NCbhZmZlaosmYh6QRJmyQ9J2m7pM+m+E2SXpa0Jd0uyuWskNQtaZekC3LxuZK2puduS9fiNjOzJqnysqoHgfMj4ueSjgN+KGng2tlfjIhb8jNLmgUsBs4CTgO+K+nMdB3uVcBS4GngMWAhvg63mVnTVLZmEZmfp4fHpVsMk7IIeCAiDkbEbqAbmCdpGjApIp6KiADuAS6pqm4zMztcpfssJE2QtAXoAzZExDPpqeskPS/pLkmTU6wd2JtL70mx9jQ9OF7r9ZZK6pLU1d/fP6rvxcxsPKu0WUTEGxExB+ggW0uYTbZJ6QxgDtAL3Jpmr7UfIoaJ13q91RHRGRGdbW1tI67fzMwyTTkaKiJ+BjwJLIyI/amJvAncAcxLs/UA03NpHcC+FO+oETczsyap8mioNkknp+mJwPuAF9I+iAGXAtvS9HpgsaTjJZ0OzAQ2RUQvcEDS/HQU1NXAuqrqNjOzw1V5NNQ0YI2kCWRNaW1EPCrpXklzyDYl7QGuBYiI7ZLWAjuAQ8DydCQUwDLgbmAi2VFQPhLKzKyJKmsWEfE8cHaN+FXD5KwEVtaIdwGzR7VAMzOrm3/BbWZmhdwszMyskJuFmZkVcrMwM7NCbhZmZlbIzcLMzAq5WZiZWSE3CzMzK+RmYWZmhdwszMyskJuFmZkVcrMwM7NCbhZmZlbIzcLMzAq5WZiZWSE3CzMzK+RmYWZmhaq8BvcJkjZJek7SdkmfTfFTJG2Q9GK6n5zLWSGpW9IuSRfk4nMlbU3P3ZauxW1mZk1S5ZrFQeD8iHg3MAdYKGk+cCOwMSJmAhvTYyTNAhYDZwELgdvT9bsBVgFLgZnptrDCus3MbJDKmkVkfp4eHpduASwC1qT4GuCSNL0IeCAiDkbEbqAbmCdpGjApIp6KiADuyeWYmVkTVLrPQtIESVuAPmBDRDwDnBoRvQDpfmqavR3Ym0vvSbH2ND04Xuv1lkrqktTV398/um/GzGwcq7RZRMQbETEH6CBbS5g9zOy19kPEMPFar7c6IjojorOtra18wWZmVlNTjoaKiJ8BT5Lta9ifNi2R7vvSbD3A9FxaB7AvxTtqxM3MrEmqPBqqTdLJaXoi8D7gBWA9sCTNtgRYl6bXA4slHS/pdLId2ZvSpqoDkuano6CuzuWYmVkTHFvh2NOANemIpmOAtRHxqKSngLWSrgFeAq4AiIjtktYCO4BDwPKIeCONtQy4G5gIPJ5uZmbWJJU1i4h4Hji7Rvw1YMEQOSuBlTXiXcBw+zvMzKxC/gW3mZkVcrMwM7NCbhZmZlbIzcLMzAq5WZiZWSE3CzMzK+RmYWZmhdwszMyskJuFmZkVcrMwM7NCbhZmZlbIzcLMzAq5WZiZWSE3CzMzK+RmYWZmhdwszMyskJuFmZkVqvIa3NMlfU/STknbJV2f4jdJelnSlnS7KJezQlK3pF2SLsjF50ramp67LV2L28zMmqTKa3AfAv4gIp6V9DZgs6QN6bkvRsQt+ZklzQIWA2cBpwHflXRmug73KmAp8DTwGLAQX4fbzKxpKluziIjeiHg2TR8AdgLtw6QsAh6IiIMRsRvoBuZJmgZMioinIiKAe4BLqqrbzMwO15R9FpJmAGcDz6TQdZKel3SXpMkp1g7szaX1pFh7mh4cr/U6SyV1Serq7+8fxXdgZja+Vd4sJL0VeAi4ISJeJ9ukdAYwB+gFbh2YtUZ6DBM/PBixOiI6I6Kzra1txLWbmVmm0mYh6TiyRnFfRDwMEBH7I+KNiHgTuAOYl2bvAabn0juAfSneUSNuZmZNUuXRUALuBHZGxBdy8Wm52S4FtqXp9cBiScdLOh2YCWyKiF7ggKT5acyrgXVV1W1mZoer8mioc4CrgK2StqTYHwFXSppDtilpD3AtQERsl7QW2EF2JNXydCQUwDLgbmAi2VFQPhLKzKyJKmsWEfFDau9veGyYnJXAyhrxLmD26FVnZmZl+BfcZmZWyM3CzMwKuVmYmVkhNwszMyvkZmFmZoXqahaSNtYTMzOzo9Owh85KOgE4EZiSzuE0cCjsJLIzw5qZ2ThQ9DuLa4EbyBrDZv6lWbwOfLnCuszMrIUM2ywi4i+Av5D0+xHxl02qyczMWkxdv+COiL+U9BvAjHxORNxTUV1mZtZC6moWku4lO634FmDgfE0DFyIyM7OjXL3nhuoEZqUr1ZmZ2ThT7+8stgFvr7IQMzNrXfWuWUwBdkjaBBwcCEbExZVUZWZmLaXeZnFTlUWYmVlrq/doqO9XXYiZmbWueo+GOkB29BPAW4DjgH+KiElVFWZmZq2jrh3cEfG2iJiUbicAHwL+argcSdMlfU/STknbJV2f4qdI2iDpxXQ/OZezQlK3pF2SLsjF50ramp67LV2L28zMmqShs85GxDeB8wtmOwT8QUS8C5gPLJc0C7gR2BgRM4GN6THpucXAWcBC4HZJE9JYq4ClwMx0W9hI3WZm1ph6N0Ndlnt4DNnvLob9zUVE9AK9afqApJ1AO7AIOC/NtgZ4EvhUij8QEQeB3ZK6gXmS9gCTIuKpVMs9wCXA4/XUbmZmI1fv0VC/k5s+BOwh+3Cvi6QZwNnAM8CpqZEQEb2SpqbZ2oGnc2k9KfbLND04bmZmTVLv0VC/1+gLSHor8BBwQ0S8PszuhlpPxDDxWq+1lGxzFe94xzvKF2tmZjXVe/GjDkmPSOqTtF/SQ5I66sg7jqxR3BcRD6fwfknT0vPTgL4U7wGm59I7gH0p3lEjfpiIWB0RnRHR2dbWVs9bMzOzOtS7g/urwHqy61q0A99KsSGlI5buBHZGxBdyT60HlqTpJcC6XHyxpOMlnU62I3tT2mR1QNL8NObVuRwzM2uCevdZtEVEvjncLemGgpxzgKuArZK2pNgfATcDayVdA7wEXAEQEdslrQV2kO0XWR4RA2e4XQbcDUwk27HtndtmZk1Ub7N4VdJHgfvT4yuB14ZLiIgfUnt/A8CCIXJWAitrxLuA2XXWamZmo6zezVAfAz4MvEJ2OOzlQMM7vc3M7MhS75rF54AlEfF/IPsVNnALWRMxM7OjXL1rFr8+0CgAIuKnZL+bMDOzcaDeZnHMoHM4nUL9ayVmZnaEq/cD/1bgf0t6kOwHcR+mxo5oMzM7OtX7C+57JHWRnTxQwGURsaPSyszMrGXUvSkpNQc3CDOzcaihU5Sbmdn44mZhZmaF3CzMzKyQm4WZmRVyszAzs0JuFmZmVsjNwszMCrlZmJlZITcLMzMr5GZhZmaFKmsWku6S1CdpWy52k6SXJW1Jt4tyz62Q1C1pl6QLcvG5kram525L1+E2M7MmqnLN4m5gYY34FyNiTro9BiBpFrAYOCvl3C5pQpp/FbAUmJlutcY0M7MKVdYsIuIHwE/rnH0R8EBEHIyI3UA3ME/SNGBSRDwVEQHcA1xSTcVmZjaUsdhncZ2k59NmqoELKrUDe3Pz9KRYe5oeHDczsyZqdrNYBZwBzAF6yS6qBNk1MgaLYeI1SVoqqUtSV39//0hrNTOzpKnNIiL2R8QbEfEmcAcwLz3VA0zPzdoB7EvxjhrxocZfHRGdEdHZ1tY2usWbmY1jTW0WaR/EgEuBgSOl1gOLJR0v6XSyHdmbIqIXOCBpfjoK6mpgXTNrNjOzElfKK0vS/cB5wBRJPcCfAOdJmkO2KWkPcC1ARGyXtJbsSnyHgOUR8UYaahnZkVUTgcfTzczMmqiyZhERV9YI3znM/CuBlTXiXcDsUSzNzMxK8i+4zcyskJuFmZkVcrMwM7NCbhZmZlbIzcLMzAq5WZiZWSE3CzMzK+RmYWZmhdwszMyskJuFmZkVcrMwM7NCbhZmZlaoshMJmrWqix7504byHrv0M6NcidmRw2sWZmZWyM3CzMwKuVmYmVkh77Owprpp7QXlcz78nQoqMbMyvGZhZmaFKmsWku6S1CdpWy52iqQNkl5M95Nzz62Q1C1pl6QLcvG5kram526TpKpqNjOz2qpcs7gbWDgodiOwMSJmAhvTYyTNAhYDZ6Wc2yVNSDmrgKXAzHQbPKaZmVWssmYRET8AfjoovAhYk6bXAJfk4g9ExMGI2A10A/MkTQMmRcRTERHAPbkcMzNrkmbvszg1InoB0v3UFG8H9ubm60mx9jQ9OF6TpKWSuiR19ff3j2rhZmbjWavs4K61HyKGidcUEasjojMiOtva2katODOz8a7ZzWJ/2rREuu9L8R5gem6+DmBfinfUiJuZWRM1u1msB5ak6SXAulx8saTjJZ1OtiN7U9pUdUDS/HQU1NW5HDMza5LKfpQn6X7gPGCKpB7gT4CbgbWSrgFeAq4AiIjtktYCO4BDwPKIeCMNtYzsyKqJwOPpZmZmTVRZs4iIK4d4asEQ868EVtaIdwGzR7E0MzMrqVV2cJuZWQtzszAzs0JuFmZmVsjNwszMCrlZmJlZITcLMzMr5GZhZmaF3CzMzKyQm4WZmRVyszAzs0JuFmZmVsjNwszMCrlZmJlZITcLMzMrVNkpyq21PPjVhQ3lXf573x7lSszsSOQ1CzMzK+RmYWZmhcakWUjaI2mrpC2SulLsFEkbJL2Y7ifn5l8hqVvSLkkXjEXNZmbj2Vjus/jtiHg19/hGYGNE3CzpxvT4U5JmAYuBs4DTgO9KOjN3jW6zceviB79VOmf95b9TQSV2tGulzVCLgDVpeg1wSS7+QEQcjIjdQDcwbwzqMzMbt8aqWQTwhKTNkpam2KkR0QuQ7qemeDuwN5fbk2KHkbRUUpekrv7+/opKNzMbf8ZqM9Q5EbFP0lRgg6QXhplXNWJRa8aIWA2sBujs7Kw5j5mZlTcmaxYRsS/d9wGPkG1W2i9pGkC670uz9wDTc+kdwL7mVWtmZk1fs5B0EnBMRBxI0+8H/gewHlgC3Jzu16WU9cDXJX2BbAf3TGBTs+seiRe+vKh0zq8tX1c80zh14boPlc55fNFDFVRiNn6MxWaoU4FHJA28/tcj4tuSfgSslXQN8BJwBUBEbJe0FtgBHAKW+0goM8t7/BuvFs9Uw4W/O2WUKzl6Nb1ZRMQ/Au+uEX8NWDBEzkpgZcWlmZnZEHxuqCPEk3d8oHTOef/5byuoxMzGo1b6nYWZmbUor1mYmY2S3s+/XDpn2idr/mys5RzVzaJ/1dcaymtb9tFRrsSsNV360A8bynvkQ+8d5UrG3o+/0lc8Uw1nf3xq8UxN1PdXTzSUN/W69w/7/FHdLMyser/7cHfpnG9c9u8qqMSq5H0WZmZWyGsWBV5Z9acN5b192WdGuRI72nzwwftK5zx6+UcqqMRayf4vbS6dc+oNcyuo5F9zszBrwAceXlU6528vW1ZBJWbN4WZhdfuf95a/7tS1V32ngkrMrNm8z8LMzAq5WZiZWSE3CzMzK+RmYWZmhdwszMyskJuFmZkVcrMwM7NCbhZmZlboiGkWkhZK2iWpW9KNY12Pmdl4ckQ0C0kTgC8DFwKzgCslzRrbqszMxo8jolkA84DuiPjHiPgF8ACwaIxrMjMbNxQRY11DIUmXAwsj4uPp8VXAf4iI6wbNtxRYmh6+E9g1zLBTgFdHWForjNEKNbTKGK1Qw2iM0Qo1tMoYrVBDq4zRrBr+TUS0DQ4eKScSVI3YYV0uIlYDq+saUOqKiM4RFdUCY7RCDa0yRivUMBpjtEINrTJGK9TQKmOMdQ1HymaoHmB67nEHsG+MajEzG3eOlGbxI2CmpNMlvQVYDKwf45rMzMaNI2IzVEQcknQd8B1gAnBXRGwf4bB1ba46AsZohRpaZYxWqGE0xmiFGlpljFaooVXGGNMajogd3GZmNraOlM1QZmY2htwszMys0LhrFpLuktQnaVuD+dMlfU/STknbJV3fwBgnSNok6bk0xmcbqSWNNUHSjyU92mD+HklbJW2R1NVA/smSHpT0Qvqb/MeS+e9Mrz1we13SDQ3U8Yn0t9wm6X5JJ5TMvz7lbq/39WstS5JOkbRB0ovpfnIDY1yR6nhTUuFhjkOM8efp3+R5SY9IOrmBMT6X8rdIekLSaWXyc8/9oaSQNKWBGm6S9HJu+bio7Bgp/vvpdEHbJX2+gTq+kathj6QtJfPnSHp64P+ZpHkN1PBuSU+l/6/fkjSpYIyan1Vll9H/LyLG1Q04F3gPsK3B/GnAe9L024C/B2aVHEPAW9P0ccAzwPwG6/lvwNeBRxvM3wNMGcHfcw3w8TT9FuDkEYw1AXiF7EdBZfLagd3AxPR4LfCfSuTPBrYBJ5Id9PFdYGYjyxLweeDGNH0j8GcNjPEush+VPgl0NljH+4Fj0/SfNVjHpNz0fwX+ukx+ik8nOzDlJ0XL2RA13AT8YYl/y1pj/Hb6Nz0+PZ5adoxBz98K/HHJGp4ALkzTFwFPNvA+fgT8Vpr+GPC5gjFqflaVXUYHbuNuzSIifgD8dAT5vRHxbJo+AOwk+7AqM0ZExM/Tw+PSrfSRBpI6gA8AXymbOxrSN5tzgTsBIuIXEfGzEQy5APiHiPhJA7nHAhMlHUv2oV/mdzjvAp6OiH+OiEPA94FLi5KGWJYWkTVQ0v0lZceIiJ0RMdzZB+oZ44n0XgCeJvttUtkxXs89PIlhltFh/l99EfjkcLl1jFG3IcZYBtwcEQfTPH2N1iFJwIeB+0vmBzCwJvArFCyfQ4zxTuAHaXoD8KGCMYb6rCq1jA4Yd81iNEmaAZxNtmZQNndCWpXtAzZEROkxgC+R/Ud8s4HcAQE8IWmzstOllPFvgX7gq2lT2FcknTSCWhYzzH/CoUTEy8AtwEtAL/B/I+KJEkNsA86V9KuSTiT75je9IGcop0ZEb6qrF5ja4Dij6WPA440kSlopaS/wEeCPS+ZeDLwcEc818to516XNYXfVvcnkXzsT+E1Jz0j6vqR/P4JafhPYHxEvlsy7Afjz9Le8BVjRwGtvAy5O01dQYhkd9FnV0DLqZtEgSW8FHgJuGPQNrC4R8UZEzCH7xjdP0uySr/9BoC8iNpd97UHOiYj3kJ3Rd7mkc0vkHku2qrwqIs4G/olstbY0ZT+2vBj4mwZyJ5N9WzodOA04SdJH682PiJ1km2o2AN8GngMODZt0hJD0abL3cl8j+RHx6YiYnvKvK5o/97onAp+mZIOpYRVwBjCH7IvArQ2McSwwGZgP/HdgbVpDaMSVNPCFhmzt5hPpb/kJ0tp4SR8j+z+6mWyz0i/qSRrpZ9UAN4sGSDqO7I9/X0Q8PJKx0mabJ4GFJVPPAS6WtIfsLLznS/paA6+/L933AY+QneG3Xj1AT26t6EGy5tGIC4FnI2J/A7nvA3ZHRH9E/BJ4GPiNMgNExJ0R8Z6IOJds9b/sN8cB+yVNA0j3w27yqJKkJcAHgY9E2kA9Al+nYLPHIGeQNe/n0jLaATwr6e1lXjQi9qcvVm8Cd1Bu+RzQAzycNv9uIlsTH3Zney1pE+dlwDcaqGEJ2XIJ2Rei0u8jIl6IiPdHxFyyhvUPRTlDfFY1tIy6WZSUvpHcCeyMiC80OEbbwNEpkiaSfdi9UGaMiFgRER0RMYNs883fRUTd36bTa58k6W0D02Q7Res+SiwiXgH2SnpnCi0AdpSpIafRb2yQbX6aL+nE9O+zgGz7bN0kTU337yD7QGi0lvVkHwyk+3UNjjMikhYCnwIujoh/bnCMmbmHF1NiGY2IrRExNSJmpGW0h2xn6ysla5iWe3gpJZbPnG8C56fxziQ7EKORs7e+D3ghInoayN0H/FaaPp8GvozkltFjgM8Af10w/1CfVY0to/XsBT+abmQfAr3AL8kW4GtK5r+XbDv/88CWdLuo5Bi/Dvw4jbGNYY6sqHO882jgaCiyfQ7Ppdt24NMNjDEH6Erv5ZvA5AbGOBF4DfiVEfwNPkv2YbYNuJd05EuJ/P9F1uieAxY0uiwBvwpsJPsw2Aic0sAYl6bpg8B+4DsNjNEN7M0to0MeyTTMGA+lv+fzwLeA9jL5g57fQ/HRULVquBfYmmpYD0xrYIy3AF9L7+VZ4PyyY6T43cB/aXC5eC+wOS1fzwBzGxjjerIjmv4euJl0Bo5hxqj5WVV2GR24+XQfZmZWyJuhzMyskJuFmZkVcrMwM7NCbhZmZlbIzcLMzAq5WZiZWSE3CzMzK/T/AGtm2Za2i1T2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_objects_stat(valset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8WUVt5FvDxdo"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6wmuEoODxdq"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if cuda.is_available() else \"cpu\") \n",
    "\n",
    "#checkpoint_path = gdrive_dir+'models/checkpoint_ssd300.pt'\n",
    "checkpoint = None #torch.load('checkpoint_path')\n",
    "vgg16_dir = 'models/'\n",
    "\n",
    "# Initiate model instance\n",
    "MySSD300 = SSD300(n_classes=21, vgg16_dir=vgg16_dir, checkpoint=checkpoint).to(device)\n",
    "\n",
    "loss_func = MultiBoxLoss(priors_cxcy=MySSD300.get_prior_boxes(), threshold=0.5, neg_pos_ratio=3, alpha=1.)\n",
    "\n",
    "optimizer = torch.optim.Adam(MySSD300.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "\n",
    "grad_clip = None\n",
    "\n",
    "# Mixed precision\n",
    "#MySSD300, optimizer = amp.initialize(MySSD300, optimizer, opt_level='O1')\n",
    "\n",
    "if checkpoint:\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "#    amp.load_state_dict(checkpoint['amp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3SGP1PteDxdv"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, trainset_loader, loss_func, optimizer, epoch_id):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for step, (imgs, boxes, labels,_) in enumerate(trainset_loader):\n",
    "        # move input data to GPU\n",
    "        imgs = imgs.to(device)\n",
    "        boxes = [b.to(device) for b in boxes]\n",
    "        labels = [l.to(device) for l in labels]\n",
    "        \n",
    "        # forward\n",
    "        predicted_offsets, predicted_scores = model(imgs)\n",
    "        loss = loss_func(predicted_offsets, predicted_scores, boxes, labels)\n",
    "        \n",
    "        # backward & optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        #with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "        #    scaled_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #if epoch_id == 1 and step % 200 == 0:\n",
    "        print(f'Epoch 1 - step {step}: train_loss: {loss.item():.4f}')\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    return train_loss/len(trainset)\n",
    "\n",
    "def eval_epoch(model, valset_loader, loss_func):\n",
    "    '''\n",
    "    '''\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for step, (imgs, boxes, labels,_) in enumerate(valset_loader):\n",
    "            # move input data to GPU\n",
    "            imgs = imgs.to(device)\n",
    "            boxes = [b.to(device) for b in boxes]\n",
    "            labels = [l.to(device) for l in labels]\n",
    "            \n",
    "            predicted_offsets, predicted_scores = model(imgs)\n",
    "            loss = loss_func(predicted_offsets, predicted_scores, boxes, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    return val_loss/len(valset)\n",
    "\n",
    "\n",
    "def train_model(model, dataloaders, optimizer, loss_func, epoch=1):\n",
    "    train_loss_hist, val_loss_hist = [], []\n",
    "    for i in range(1,epoch+1):\n",
    "        start_time = time.time()\n",
    "        train_loss = train_epoch(model, dataloaders['train'], loss_func, optimizer, i)\n",
    "        training_time = round(time.time() - start_time)\n",
    "        \n",
    "        # save_checkpoint(epoch, model, optimizer) #every 3 epoch\n",
    "        if i % 3 == 0:\n",
    "            torch.save({'epoch': i, \n",
    "                        'model': model.state_dict(), \n",
    "                        'optimizer': optimizer.state_dict(), \n",
    "                        #'amp': amp.state_dict()\n",
    "                       }, checkpoint_path)\n",
    "            print(f'Epoch {i} - Model saved at checkpoint_path | Time consumed: {round(time.time()-training_time)}s')\n",
    "        \n",
    "        start_time = time.time()\n",
    "        val_loss = eval_epoch(model, dataloaders['val'], loss_func)\n",
    "        val_time = round(time.time() - start_time)\n",
    "        \n",
    "        train_loss_hist.append(train_loss)\n",
    "        val_loss_hist.append(val_loss)\n",
    "        \n",
    "        print(f'Epoch {i} - train/val_time: {training_time}s | {val_time}s - train_loss: {train_loss:.4f} - val_loss: {val_loss:.4f}')\n",
    "        \n",
    "    return train_loss_hist, val_loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "colab_type": "code",
    "id": "2vY_0FEADxd0",
    "outputId": "b519865a-63e2-4638-d660-94043b1c5470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - step 0: train_loss: 33.4896\n",
      "Epoch 1 - step 1: train_loss: 13.6597\n",
      "Epoch 1 - step 2: train_loss: 13.4090\n",
      "Epoch 1 - step 3: train_loss: 13.4923\n",
      "Epoch 1 - step 4: train_loss: 13.7203\n",
      "Epoch 1 - step 5: train_loss: 13.7206\n",
      "Epoch 1 - step 6: train_loss: 13.3404\n",
      "Epoch 1 - step 7: train_loss: 13.2686\n",
      "Epoch 1 - step 8: train_loss: 13.2957\n",
      "Epoch 1 - step 9: train_loss: 13.3048\n",
      "Epoch 1 - step 10: train_loss: 13.4261\n",
      "Epoch 1 - step 11: train_loss: 13.3851\n",
      "Epoch 1 - step 12: train_loss: 13.4661\n",
      "Epoch 1 - step 13: train_loss: 13.3052\n",
      "Epoch 1 - step 14: train_loss: 14.6179\n",
      "Epoch 1 - step 15: train_loss: 13.3202\n",
      "Epoch 1 - step 16: train_loss: 13.2782\n",
      "Epoch 1 - step 17: train_loss: 13.3751\n",
      "Epoch 1 - step 18: train_loss: 13.4024\n",
      "Epoch 1 - step 19: train_loss: 13.2425\n",
      "Epoch 1 - step 20: train_loss: 13.3706\n",
      "Epoch 1 - step 21: train_loss: 13.2639\n",
      "Epoch 1 - step 22: train_loss: 13.3075\n",
      "Epoch 1 - step 23: train_loss: 13.2949\n",
      "Epoch 1 - step 24: train_loss: 13.3153\n",
      "Epoch 1 - step 25: train_loss: 13.3801\n",
      "Epoch 1 - step 26: train_loss: 13.2898\n",
      "Epoch 1 - step 27: train_loss: 13.3546\n",
      "Epoch 1 - step 28: train_loss: 13.3777\n",
      "Epoch 1 - step 29: train_loss: 13.3433\n",
      "Epoch 1 - step 30: train_loss: 13.2662\n",
      "Epoch 1 - step 31: train_loss: 13.2484\n",
      "Epoch 1 - step 32: train_loss: 13.2948\n",
      "Epoch 1 - step 33: train_loss: 13.1880\n",
      "Epoch 1 - step 34: train_loss: 13.3221\n",
      "Epoch 1 - step 35: train_loss: 13.2658\n",
      "Epoch 1 - step 36: train_loss: 13.1985\n",
      "Epoch 1 - step 37: train_loss: 13.2588\n",
      "Epoch 1 - step 38: train_loss: 13.2919\n",
      "Epoch 1 - step 39: train_loss: 13.3148\n",
      "Epoch 1 - step 40: train_loss: 13.2598\n",
      "Epoch 1 - step 41: train_loss: 13.3512\n",
      "Epoch 1 - step 42: train_loss: 13.2851\n",
      "Epoch 1 - step 43: train_loss: 13.2527\n",
      "Epoch 1 - step 44: train_loss: 12.9871\n",
      "Epoch 1 - step 45: train_loss: 13.2548\n",
      "Epoch 1 - step 46: train_loss: 13.2236\n",
      "Epoch 1 - step 47: train_loss: 13.2638\n",
      "Epoch 1 - step 48: train_loss: 13.3685\n",
      "Epoch 1 - step 49: train_loss: 13.1895\n",
      "Epoch 1 - step 50: train_loss: 13.3439\n",
      "Epoch 1 - step 51: train_loss: 13.2876\n",
      "Epoch 1 - step 52: train_loss: 13.2528\n",
      "Epoch 1 - step 53: train_loss: 13.3297\n",
      "Epoch 1 - step 54: train_loss: 13.3368\n",
      "Epoch 1 - step 55: train_loss: 13.2696\n",
      "Epoch 1 - step 56: train_loss: 13.3190\n",
      "Epoch 1 - step 57: train_loss: 13.2930\n",
      "Epoch 1 - step 58: train_loss: 13.2395\n",
      "Epoch 1 - step 59: train_loss: 13.2657\n",
      "Epoch 1 - step 60: train_loss: 13.2578\n",
      "Epoch 1 - step 61: train_loss: 13.2469\n",
      "Epoch 1 - step 62: train_loss: 13.2875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-89b698fd4ee7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_loss_hist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss_hist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMySSD300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-6183e317cd7a>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloaders, optimizer, loss_func, epoch)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mtraining_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-6183e317cd7a>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, trainset_loader, loss_func, optimizer, epoch_id)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# backward & optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;31m#with amp.scale_loss(loss, optimizer) as scaled_loss:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m#    scaled_loss.backward()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfe\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfe\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss_hist, val_loss_hist = train_model(MySSD300, dataloaders, optimizer, loss_func, epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T6_OV2liYjEw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, valset_loader, loss_func):\n",
    "    '''\n",
    "    '''\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    \n",
    "    detected_boxes = list()\n",
    "    detected_labels = list()\n",
    "    detected_scores = list()\n",
    "    true_boxes = list()\n",
    "    true_labels = list()\n",
    "    true_diffs = list()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, (imgs, boxes, labels, diffs) in enumerate(valset_loader):\n",
    "            # move input data to GPU\n",
    "            imgs = imgs.to(device)\n",
    "            boxes = [b.to(device) for b in boxes]\n",
    "            labels = [l.to(device) for l in labels]\n",
    "            diffs = [d.to(device) for d in diffs]\n",
    "\n",
    "            # detect objects\n",
    "            predicted_offsets, predicted_scores = model(imgs)\n",
    "            batch_det_boxes, batch_det_labels, batch_det_scores = model.detect_objects(predicted_offsets, predicted_scores,\n",
    "                                                                                       score_threshold=0.01, iou_threshold=0.5)\n",
    "            # calculate val loss\n",
    "            loss = loss_func(predicted_offsets, predicted_scores, boxes, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            detected_boxes.extend(batch_det_boxes)\n",
    "            detected_labels.extend(batch_det_labels)\n",
    "            detected_scores.extend(batch_det_scores)\n",
    "            true_boxes.extend(boxes)\n",
    "            true_labels.extend(labels)\n",
    "            true_diffs.extend(diffs)\n",
    "\n",
    "        # calculate metrics value\n",
    "        APs, mAP = calculate_mAP(detected_boxes, detected_labels, detected_scores, true_boxes, true_labels, true_diffs)\n",
    "        val_loss = val_loss/len(valset)\n",
    "    \n",
    "    return val_loss, APs, mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "train-eval.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
